{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf49906-8ab2-4369-9c6c-ab24953e90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from pymongo import MongoClient\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd9dc02-299d-4546-ba66-bb0aec95e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JuralParser:\n",
    "    \n",
    "    def __init__(self, mongoUrl):\n",
    "        self.mongoUrl = mongoUrl\n",
    "        self.databaseName=\"JuralDetails\"\n",
    "        self.collectionName=\"AllDetails\"\n",
    "        client = MongoClient(self.mongoUrl)\n",
    "        db = client[self.databaseName]\n",
    "        self.collection = db[self.collectionName]\n",
    "        self.collection.create_index(\"title\", unique=True)\n",
    "    \n",
    "    # Добавляет в БД уникальные записи\n",
    "    def add_data(self, product_data):\n",
    "        try:\n",
    "            self.collection.insert_one(product_data)\n",
    "        except:\n",
    "            logging.info(f\"{product_data['title']} уже существует\")\n",
    "        \n",
    "    \n",
    "    # Поиск деталей по цене\n",
    "    def get_details_with_greater_price(self, price:str = 0):\n",
    "        query = {\"price\" : {\"$gt\": price}}\n",
    "        documents = self.collection.find(query)\n",
    "        return documents\n",
    "\n",
    "    \n",
    "    def print_data(self, data):\n",
    "        for d in data:\n",
    "            print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae9b040c-14d4-4009-88de-bec221a5f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JuralSpider(scrapy.Spider):\n",
    "    name = 'jural_spider'\n",
    "    start_urls = ['https://agroteh26.ru/catalog/19-zapchasti_dlya_selhoztehniki/13-katalog_zapchastej_mtz_/dvigateli/']\n",
    "    max_pages = 5\n",
    "    juralParser = JuralParser(mongoUrl=\"mongodb://localhost:27017/PSU\")\n",
    "    custom_settings = {\n",
    "        \"LOG_FILE\": \"scrapy.log\",\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Извлекаем данные с текущей страницы\n",
    "        for item in response.css('div.product-card'):\n",
    "            title = item.css('div.product-card__name a::text').get(default='Нет названия').strip()\n",
    "            article = item.css('div.product-card__info span[itemprop=\"model\"]::text').get(default='Нет артикула').strip()\n",
    "            manufacturer = item.css('div.product-card__info span[itemprop=\"brand\"]::text').get(default='Нет производителя').strip()\n",
    "            price = item.css('div.product-card__prices meta[itemprop=\"price\"]::attr(content)').get(default='0')\n",
    "\n",
    "            product_data = {\n",
    "                \"title\": title,\n",
    "                \"article\": article,\n",
    "                \"manufacturer\": manufacturer,\n",
    "                \"price\": int(price.replace(\" \", \"\"))\n",
    "            }\n",
    "\n",
    "            self.juralParser.add_data(product_data)\n",
    "\n",
    "        current_page = response.url.split('page=')[-1]\n",
    "        if len(current_page) > 2:\n",
    "            current_page = '1'\n",
    "            \n",
    "        page_number = int(current_page)\n",
    "        \n",
    "        if page_number < self.max_pages:\n",
    "            next_page = page_number + 1\n",
    "            next_page_url = self.start_urls[0] + f'?page={next_page}'\n",
    "            yield scrapy.Request(next_page_url, callback=self.parse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10d7296b-d4b9-4a44-bc17-9f3dfb83f1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 17:02:49 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2024-11-27 17:02:49 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Windows-10-10.0.19045-SP0\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess()\n",
    "\n",
    "process.crawl(JuralSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265d0e8-0dce-4ff1-8ffc-b8cddba6460e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
